import cv2
import json
import os
import numpy as np
import torch
from facenet_pytorch import MTCNN, InceptionResnetV1
from torchvision import transforms
import multiprocessing

#ì–¼êµ´ ì¸ì‹ë§Œ í•˜ëŠ” í´ë˜ìŠ¤ jsonì—ì„œ ë°ì´í„° ë¡œë“œ
class FaceDetect:
    IMG_SRC_FOLDER = "/home/addinedu/venv/develop/project/cv/img_src"
    METADATA_PATH = os.path.join(IMG_SRC_FOLDER, "face_metadata.json")  # ì–¼êµ´ ë©”íƒ€ë°ì´í„° ê²½ë¡œ

    def __init__(self,latest_worker):
        # CUDA ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if torch.cuda.is_available():
            print(f"Using GPU: {torch.cuda.get_device_name(0)}")
        else:
            print("Using CPU")
        self.mtcnn = MTCNN(keep_all=False, device=self.device)  # í•˜ë‚˜ì˜ ì–¼êµ´ë§Œ ê°ì§€
        #ì–¼êµ´ë¹„êµëª¨ë¸ facenet
        self.facenet = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)
        self.reference_embeddings = self.load_embeddings()  # ê¸°ì¡´ ì–¼êµ´ ë°ì´í„° ë¡œë“œ
        self.latest_worker = latest_worker  # ê³µìœ  ë©”ëª¨ë¦¬ ê°ì²´
        self.last_valid_worker = None  # "No Match"ê°€ ì•„ë‹ ë•Œì˜ ìµœê·¼ ì‚¬ìš©ì ì €ì¥


    #ì„ë² ë”© ì •ë³´ ë¡œë“œ
    def load_embeddings(self):
        if os.path.exists(self.METADATA_PATH):
            with open(self.METADATA_PATH, "r", encoding="utf-8") as file:
                try:
                    metadata = json.load(file)
                except json.JSONDecodeError:
                    metadata = {}
        else:
            metadata = {}
        return {id: np.array(data["embedding"]) for id, data in metadata.items()}

    #ì–¼êµ´ ê°ì§€ ë° ì„ë² ë”© ì¶”ì¶œ
    def extract_embedding(self, image):
        boxes, _ = self.mtcnn.detect(image)
        if boxes is not None and len(boxes) > 0:
            x1, y1, x2, y2 = [int(b) for b in boxes[0]]
            face = image[max(y1, 0):min(y2, image.shape[0]), max(x1, 0):min(x2, image.shape[1])]
            if face.size == 0:
                return None, None
            transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((160, 160)),
                transforms.ToTensor(),
                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
            ])
            face_tensor = transform(face).unsqueeze(0).to(self.device)
            embedding = self.facenet(face_tensor).detach().cpu().numpy().flatten()
            return embedding, boxes[0]
        return None, None

    #ì–¼êµ´ë¹„êµ -> ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
    def calculate_distance(self, embedding1, embedding2):
        return np.linalg.norm(embedding1 - embedding2)

    # main -> ìº  ì—´ê³  ë§¤ì¹­
    def recognize_face(self):
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 600)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        if not cap.isOpened():
            print("Failed to open webcam.")
            return

        print("Press 'q' to quit.")

        frame_count = 0 #í”„ë ˆì„ ì¹´ìš´í„° -> ìƒíƒœ ì—…ë°ì´íŠ¸ íšŸìˆ˜ ì¡°ì • 

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                print("Failed to read from webcam.")
                break

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            embedding, box = self.extract_embedding(frame_rgb)

            if embedding is not None:
                best_match = "No Match"
                min_distance = float('inf')

                #ì €ì¥ëœ ì–¼êµ´ ë°ì´í„°ë‘ í˜„ì¬ ì–¼êµ´ì˜ ì„ë² ë”©ì„ ë¹„êµí•˜ê³ , ê°€ì¥ ê°€ê¹Œìš´ ì‘ì—…ì ì°¾ê¸°
                for user_id, ref_embedding in self.reference_embeddings.items():
                    distance = self.calculate_distance(ref_embedding, embedding)
                    if distance < min_distance:
                        min_distance = distance
                        best_match = user_id if min_distance < 0.85 else "No Match"
                
                if best_match != "No Match":
                    self.last_valid_worker = best_match

                # ì‚¬ìš©ì ë°”ë€” ë•Œ ìƒíƒœ ì¶œë ¥
                if frame_count % 15 == 0 and self.latest_worker.value != self.last_valid_worker:
                    self.latest_worker.value = self.last_valid_worker if self.last_valid_worker is not None else "No Match"
                    print(f"ğŸ”¹ ìµœê·¼ ê°ì§€ëœ ì‚¬ìš©ì: {self.latest_worker.value}")
                
                frame_count += 1



                #ë°”ìš´ë”© ë°•ìŠ¤ ë° í…ìŠ¤íŠ¸ í‘œì‹œ
                x1, y1, x2, y2 = [int(b) for b in box]
                color = (0, 255, 0) if best_match != "No Match" else (0, 0, 255)
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(frame, best_match, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                

            cv2.imshow("Face Detection", frame)
            if cv2.waitKey(30) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    manager = multiprocessing.Manager()
    latest_worker = manager.Value("s", "No Match")  # ê³µìœ  ë©”ëª¨ë¦¬ ìƒì„±

    detector = FaceDetect(latest_worker)  # âœ… latest_worker ì „ë‹¬
    detector.recognize_face()
