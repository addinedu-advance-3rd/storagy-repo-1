import rclpy
from rclpy.node import Node
from rclpy.action import ActionServer
from package_msg.action import ActionMessages
import numpy as np
import cv2
from ultralytics import YOLO
from xarm.wrapper import XArmAPI
import time

class XArmActionServer(Node):
    def __init__(self):
        super().__init__('xarm_control')

        # ì•¡ì…˜ ì„œë²„ ì´ˆê¸°í™”
        self.action_server = ActionServer(
            self,
            ActionMessages,
            'action_messages',
            self.execute_callback
        )

        # ì €ì¥ëœ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì •ë³´ ë¡œë“œ
        self.camera_matrix = np.load("/home/addinedu/camera_matrix.npy")
        self.dist_coeffs = np.load("/home/addinedu/dist_coeffs.npy")
        self.homography_matrix = np.load("/home/addinedu/homography_matrix2.npy")

        # ë¡œë´‡íŒ” ì´ˆê¸°í™”
        self.arm = XArmAPI("192.168.1.182")
        self.arm.motion_enable(enable=True)
        self.arm.set_mode(0)
        self.arm.set_state(0)

        # YOLO ëª¨ë¸ ë¡œë“œ
        self.model = YOLO("/home/addinedu/tools_ver3/weights/best.pt")
        self.cap = cv2.VideoCapture(0)

        # ê°ì§€í•  ê³µêµ¬ ë¦¬ìŠ¤íŠ¸ (ì‹¤ì œ ëª¨ë¸ í´ë˜ìŠ¤ëª… í™•ì¸ í›„ ìˆ˜ì • í•„ìš”!)
        self.tool_priority = ["Driver", "Spanner", "Hammer"]

        # ë„êµ¬ë¥¼ ë‚´ë ¤ë†“ì„ ì¢Œí‘œ (ê°ê° ë„êµ¬ì— ëŒ€ì‘)
        self.drop_positions = {
            "Driver": (-123, -320, 330, 180, 0, 90),
            "Spanner": (-14, -320, 330, 180, 0, 90),
            "Hammer": (111.2, -320, 330, 180, 0, 90)
        }

        # í™ˆ í¬ì§€ì…˜ ì •ì˜
        self.home_position = (-8, -174, 450, 180, 0, 90)
        self.tool_positions = {}

    def execute_callback(self, goal_handle):
        """'ë„ì°©' í‚¤ì›Œë“œë¥¼ ë°›ìœ¼ë©´ ë¡œë´‡ ë™ì‘ ì‹¤í–‰ â†’ ì™„ë£Œ í›„ 'ì™„ë£Œ' ë°˜í™˜"""
        self.get_logger().info('ğŸ“© "ë„ì°©" ì‹ í˜¸ ìˆ˜ì‹ , ì‘ì—… ì‹œì‘!')

        # í”¼ë“œë°±ì„ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡ (ì‘ì—… ì¤‘ì„ì„ ì•Œë¦¼)
        feedback_msg = ActionMessages.Feedback()
        #self.get_logger().info(f"ğŸ§ ë””ë²„ê¹…: {dir(feedback_msg)}")

        feedback_msg.feedback = "ì‘ì—…ì„ ìˆ˜í–‰ ì¤‘.."
        goal_handle.publish_feedback(feedback_msg)

        # ë„êµ¬ ê°ì§€
        self.detect_tools()
        if not self.tool_positions:
            self.get_logger().warn("âš ï¸ ë„êµ¬ ê°ì§€ ì‹¤íŒ¨!")
            goal_handle.abort()
            return ActionMessages.Result(result="ë„êµ¬ ê°ì§€ ì‹¤íŒ¨")
        
        for tool in self.tool_priority:
            if tool not in self.tool_positions:
                self.get_logger().warn(f"âš ï¸ {tool} ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ê±´ë„ˆëœë‹ˆë‹¤.")
                continue  # ë„êµ¬ ê°ì§€ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆëœ€

            # í”½ì…€ ì¢Œí‘œ â†’ ë¡œë´‡ ì¢Œí‘œ ë³€í™˜
            pick_coords = list(self.pixel_to_robot(*self.tool_positions[tool][:2]))  # ë¦¬ìŠ¤íŠ¸ ë³€í™˜
            angle = self.tool_positions[tool][2]  # ì¶”ì¶œëœ ê°ë„ (degree ë‹¨ìœ„)

            if angle is not None:
                # ê°ë„ë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜
                angle_rad = np.radians(angle)

                # x, y ì¢Œí‘œ ë³´ì •
                pick_coords[0] += 140 * np.cos(angle_rad)  
                pick_coords[1] += 140 * np.sin(angle_rad)

            # âœ… ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì—ì„œ í˜¸ì¶œ (ëª¨ë“  ë„êµ¬ ì´ë™)
            self.move_to_tool(tool, pick_coords, angle)

        self.get_logger().info("ğŸ”„ ëª¨ë“  ì‘ì—… ì™„ë£Œ! í™ˆ í¬ì§€ì…˜ìœ¼ë¡œ ë³µê·€ ì¤‘...")
        self.arm.set_position(*self.home_position, speed=200, mvacc=100, wait=True)  # ëª¨ë“  ì‘ì—… í›„ í™ˆ í¬ì§€ì…˜ ë³µê·€

        # âœ… ì‘ì—… ì™„ë£Œ í›„ 'ì™„ë£Œ' í‚¤ì›Œë“œ ë°˜í™˜
        goal_handle.succeed()
        return ActionMessages.Result(result="ì™„ë£Œ")
        
    def pixel_to_robot(self, x, y, fixed_z=450, roll=180, pitch=0, yaw=90):
        """í”½ì…€ ì¢Œí‘œë¥¼ ë¡œë´‡ ì¢Œí‘œë¡œ ë³€í™˜"""
        src_pixel = np.array([[x, y]], dtype=np.float32)
        dst_pixel = cv2.undistortPoints(src_pixel, self.camera_matrix, self.dist_coeffs, P=self.camera_matrix)
        src = np.array([[dst_pixel[0][0][0], dst_pixel[0][0][1], 1]], dtype=np.float32).T
        dst = np.dot(self.homography_matrix, src)
        dst /= dst[2]
        return (dst[0].item(), dst[1].item(), fixed_z, roll, pitch, yaw)

    def estimate_angle_pca(self, mask):
        mask = cv2.GaussianBlur(mask, (5, 5), 0)
        points = np.column_stack(np.where(mask > 0))
        if len(points) < 10:
            return None, None
        mean, eigenvectors = cv2.PCACompute(points.astype(np.float32), mean=None)
        if mean is None or eigenvectors is None or len(eigenvectors) == 0:
            return None, None
        principal_axis = eigenvectors[0]
        #angle = np.arctan2(principal_axis[1], principal_axis[0]) * (180 / np.pi) + 90
        angle = np.arctan2(principal_axis[1], principal_axis[0]) * (180 / np.pi)
        angle = (angle + 360) % 180 # ê¸°ì¤€ì„ 0ë„ë¡œ ì„¤ì •
        if angle < 90:
            angle = angle + 90
        else:
            angle = angle - 90

        return angle, tuple(mean.flatten().astype(int))

    def detect_tools(self):
        """YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ ê°ì§€"""
        self.tool_positions.clear()
        ret, frame = self.cap.read()
        if not ret:
            self.get_logger().error("âŒ ì¹´ë©”ë¼ ì˜ìƒì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        detect_results = self.model(frame, verbose=False)
        for results in detect_results:
            if results.masks is not None:
                for mask, box, cls in zip(results.masks.data.cpu().numpy(), results.boxes.xyxy.cpu().numpy(), results.boxes.cls.cpu().numpy()):
                    class_name = self.model.names[int(cls)]
                    if class_name in self.tool_priority:
                        mask = (mask * 255).astype(np.uint8)
                        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        for cnt in contours:
                            if cv2.contourArea(cnt) > 500:
                                M = cv2.moments(cnt)
                                if M["m00"] != 0:
                                    cx = int(M["m10"] / M["m00"])
                                    cy = int(M["m01"] / M["m00"])
                                    bbox_cx = int((box[0] + box[2]) / 2)
                                    bbox_cy = int((box[1] + box[3]) / 2)
                                    final_cx = int((cx + bbox_cx) / 2)
                                    final_cy = int((cy + bbox_cy) / 2)
                                    angle, _ = self.estimate_angle_pca(mask)
                                    if angle is not None:
                                        self.tool_positions[class_name] = (final_cx, final_cy, angle)

        self.get_logger().info(f"ğŸ” ê°ì§€ëœ ë„êµ¬: {self.tool_positions}")
        
    def move_to_tool(self, tool_name, pick_coords, angle):
        """ë¡œë´‡íŒ”ì„ ì´ë™í•˜ì—¬ ë„êµ¬ë¥¼ ì§‘ê³  ì§€ì •ëœ ìœ„ì¹˜ì— ë†“ìŒ"""
        self.get_logger().info(f"ğŸš€ {tool_name} ìœ„ì¹˜ë¡œ ì´ë™: {pick_coords}, íšŒì „ ê°ë„: {angle:.2f}Â°")
        
        # ê³µêµ¬ ì¡ê¸° ìœ„í•´ ì›€ì§ì´ëŠ” ê³¼ì •
        self.arm.close_lite6_gripper() 
        self.arm.set_position(*pick_coords, speed=200, mvacc=100, wait=True)
        self.arm.set_position(pick_coords[0], pick_coords[1], pick_coords[2], pick_coords[3], pick_coords[4], angle, speed=200, mvacc=100, wait=True)
        time.sleep(1)
        self.arm.set_position(pick_coords[0], pick_coords[1], 320, pick_coords[3], pick_coords[4], angle, speed=200, mvacc=100, wait=True)
        
        # ê³µêµ¬ ì¡ê¸°
        self.arm.open_lite6_gripper()
        time.sleep(1)

        # ê³µêµ¬ ì¡ì€ í›„ ë“¤ì–´ì˜¬ë¦¬ê¸°
        self.arm.set_position(*pick_coords, speed=200, mvacc=100, wait=True)
        
        # ê³µêµ¬ ì •ë¦¬í•˜ê¸° ìœ„í•´ ì›€ì§ì´ëŠ” ê³¼ì •
        drop_coords = self.drop_positions[tool_name]
        self.get_logger().info(f"ğŸ“ {tool_name}ì„(ë¥¼) {drop_coords} ìœ„ì¹˜ë¡œ ì´ë™")
        self.arm.set_position(drop_coords[0], drop_coords[1], 450, drop_coords[3], drop_coords[4], drop_coords[5], speed=200, mvacc=100, wait=True)
        self.arm.set_position(*drop_coords, speed=200, mvacc=100, wait=True)
        
        # ê³µêµ¬ ë†“ê¸°
        self.arm.close_lite6_gripper()
        time.sleep(1)

        # ê³µêµ¬ ë†“ì€ í›„ 
        self.arm.set_position(drop_coords[0], drop_coords[1], 450, drop_coords[3], drop_coords[4], drop_coords[5], speed=200, mvacc=100, wait=True)

    def destroy_node(self):
        """ë…¸ë“œ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜"""
        self.get_logger().info("ğŸ›‘ ì„œë²„ ì¢…ë£Œ ì¤‘... ì¹´ë©”ë¼ ì¢…ë£Œ")
        
        if self.cap.isOpened():
            self.cap.release()  # âœ… ì¹´ë©”ë¼ í•´ì œ
            self.get_logger().info("ğŸ“¸ ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        cv2.destroyAllWindows()  # âœ… ëª¨ë“  OpenCV ì°½ ë‹«ê¸°
        super().destroy_node()

def main(args = None):
    rclpy.init(args=args)
    node = XArmActionServer()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()
    
if __name__ == "__main__":
    main()

